{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ESSE Classificação de Sentimentos com BERT e Embedding",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tadN4hSCP9p"
      },
      "source": [
        "# Etapa 1: Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUU4TlmoFMZ_"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXj8lk3uGn4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f45fc9-47b2-41af-f4a8-02e600ee6390"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/a1/acb891630749c56901e770a34d6bac8a509a367dd74a05daf7306952e910/bert-for-tf2-0.14.9.tar.gz (41kB)\n",
            "\r\u001b[K     |████████                        | 10kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.8MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/e0/4f663d8abf83c8084b75b995bd2ab3a9512ebc5b97206fde38cef906ab07/py-params-0.10.2.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-cp37-none-any.whl size=30535 sha256=52a3fed770b4df7be310ce24100ffa4cd9ce6fb21f9e56efd3562303ec0ad6bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/04/ee/347bd9f5b821b637c76411d280271a857aece00358896a230f\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-cp37-none-any.whl size=7912 sha256=28ce1ada2821acaeabf2ed85a4219034c411286e61b8948ba637736bff045af7\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/4a/70/ff12450229ff1955abf01f365051d4faae1c20aef53ab4cf09\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp37-none-any.whl size=19472 sha256=f085541050d96656a1f5e85e8e7a5bc09ef180680c3e8af572bb8e0279f33360\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 10.8MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2dpIAA8X-gi",
        "outputId": "5a1508fb-c415-46bd-9687-9a574bc4b970"
      },
      "source": [
        "!pip install tensorflow==2.2.0-rc3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.2.0-rc3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/11/e1430cf2d2196a67c42bb761fa19e46dc08de52abfe90fbdad390eb41dca/tensorflow-2.2.0rc3-cp37-cp37m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2MB 32kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (3.12.4)\n",
            "Collecting tensorboard<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 37.3MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 34.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (1.12.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (1.1.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (1.6.3)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (1.4.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (3.3.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (2.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0-rc3) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow==2.2.0-rc3) (56.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (1.28.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (0.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (1.24.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (3.10.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0-rc3) (3.1.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed tensorboard-2.2.2 tensorflow-2.2.0rc3 tensorflow-estimator-2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOfuPdFHFpfC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b3669848-a70a-4583-cd73-cb7000340b0d"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert\n",
        "tf.__version__\n",
        "# !pip install tensorflow==2.2.0-rc3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0-rc3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6ZbE2lPDIFL"
      },
      "source": [
        "# Etapa 2: Pré-processamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9S77lewDNE1"
      },
      "source": [
        "## Carregamento dos arquivos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hABc0h8GdTe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "293ba02e-a2df-489d-bd0f-8cf6a1c38366"
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slnILsqwGxTX"
      },
      "source": [
        "cols = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
        "data = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/IA MachineLearning DataSciense/BERT-classificacao_sentimentos/training.1600000.processed.noemoticon.csv\",\n",
        "    header=None,\n",
        "    names=cols,\n",
        "    engine=\"python\",\n",
        "    encoding=\"latin1\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REdK4z4YG9kZ"
      },
      "source": [
        "data.drop([\"id\", \"date\", \"query\", \"user\"],\n",
        "          axis=1,\n",
        "          inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bNsUauVDAx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec770c04-5b67-4406-e0ec-f4235cc3d8a2"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6F86zv3C-11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "dc318bae-69a1-4531-e851-ad23da0be6fc"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0  @nationwideclass no, it's not behaving at all...."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz2g61evDZb4"
      },
      "source": [
        "## Pré-processamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCyy4babDrI8"
      },
      "source": [
        "### Limpeza"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEyorQS_HArn"
      },
      "source": [
        "def clean_tweet(tweet):\n",
        "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
        "    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
        "    tweet = re.sub(r\" +\", ' ', tweet)\n",
        "    return tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BlbZpy0HHiV"
      },
      "source": [
        "data_clean = [clean_tweet(tweet) for tweet in data.text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6SOj46BHKEk"
      },
      "source": [
        "data_labels = data.sentiment.values\n",
        "data_labels[data_labels == 4] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJa3YWeJD1gM"
      },
      "source": [
        "### Tokenização"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wry-st-HMN0"
      },
      "source": [
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False) #BERT smool. não é o large\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = FullTokenizer(vocab_file, do_lower_case) #vocab_file = todas as palavras em ingles, do_lower_case = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0C5YknYak5V",
        "outputId": "8d3202d7-d5ef-4fe7-c546-01f330fd57b8"
      },
      "source": [
        "vocab_file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'/tmp/tfhub_modules/03d6fb3ce1605ad9e5e9ed5346b2fb9623ef4d3d/assets/vocab.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChImhXVqapw0",
        "outputId": "3fd05cd4-c2fe-4cc7-e2bf-435cf990bd2c"
      },
      "source": [
        "do_lower_case"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAwvS1bNmXCo"
      },
      "source": [
        "def encode_sentence(sent):\n",
        "  return [\"[CLS]\"] + tokenizer.tokenize(sent) + [\"[SEP]\"]\n",
        "#CLS = token para classificação\n",
        "#SEP = token de separação para a sentença B. Mesmo que não tenha uma sentença B, é preciso colocar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efeM4ecPmySl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0da0630b-83b7-4ac6-c4ad-e6ebda74d49a"
      },
      "source": [
        "encode_sentence(\"My dog likes strawberries.\")\n",
        "#essa será a formatação para a base de dados, ou seja, o input para o algoritmo BERT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]', 'my', 'dog', 'likes', 'straw', '##berries', '.', '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIQQiZjlm91C"
      },
      "source": [
        "#para cada registro do texto da base de dados, faz a separação, como antes\n",
        "data_inputs = [encode_sentence(sentence) for sentence in data_clean]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhDeFvNGoJec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c0a1ce-c606-4ced-f500-cf63290490c3"
      },
      "source": [
        "#buscando os dois primeiros registros\n",
        "print(data_inputs[0:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['[CLS]', 'aw', '##w', '##w', 'that', \"'\", 's', 'a', 'bum', '##mer', '.', 'you', 'should', '##a', 'got', 'david', 'carr', 'of', 'third', 'day', 'to', 'do', 'it', '.', 'd', '[SEP]'], ['[CLS]', 'is', 'upset', 'that', 'he', 'can', \"'\", 't', 'update', 'his', 'facebook', 'by', 'text', '##ing', 'it', '.', '.', '.', 'and', 'might', 'cry', 'as', 'a', 'result', 'school', 'today', 'also', '.', 'blah', '!', '[SEP]']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z32MeEwnkCB8"
      },
      "source": [
        "### Criação da base de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXhE6rEna34_"
      },
      "source": [
        "MODELO RECEBE 3 PARÂMETROS DIFERENTES, não apenas só as frases:\n",
        "\n",
        "PRECISA RECEBER:\n",
        "\n",
        "1)converte o id dos tokens: valores dos tokens\n",
        "\n",
        "2)máscara: onde está o token de padding: é preciso que todas as frases tenham o mesmo tamanho. Logo, se uma frase tiver 5 tokens e outra 8 tokens, é preciso preencher a sentença de 5 tokens para 8 tokens, adicionando caracter especial chamado padding, retornando 0:false ou 1:true\n",
        "\n",
        "3)Lista de 0: tokens da primeira sentença; 1: valores da segunda sentença. Maneira de indicar quando uma sentença começa ou termica\n",
        "My dog is  SEP My cat is\n",
        "0   0   0      1   1   1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlcZpE8goS6f"
      },
      "source": [
        "#1º TIPO DE ENTRADA\n",
        "def get_ids(tokens):\n",
        "  return tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ2q_UYWogui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "651d8f93-4d4c-4b0d-ce55-84552c357d3b"
      },
      "source": [
        "get_ids(tokenizer.tokenize(\"My dog likes strawberries.\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2026, 3899, 7777, 13137, 20968, 1012]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDFzOY-fpXvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b35a7de-c6ff-4af0-b927-6889ceec6048"
      },
      "source": [
        "#compara cada token da sentença com o caracter PAD\n",
        "np.char.not_equal(\"[PAD]\", \"[PAD]\") #não são diferentes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKkjSLElouOD"
      },
      "source": [
        "#2º TIPO DE ENTRADA\n",
        "def get_mask(tokens):\n",
        "  return np.char.not_equal(tokens, \"[PAD]\").astype(int)   #converte para o tipo inteiro o true ou false\n",
        "#[PAD] = indica que haverá um tipo de preenchimento se as sentenças não forem iguais em tamanho"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNZjB4tGpmie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be3c9a44-a88b-41e8-9462-c076b3bcea5a"
      },
      "source": [
        "get_mask(tokenizer.tokenize(\"My dog likes strawberries.\"))\n",
        "#nessa sentença, não tem o token PAD. Se tivesse o token pad, então seria colocado 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE5JsrM4qWFC"
      },
      "source": [
        "#3º TIPO DE ENTRADA\n",
        "def get_segments(tokens):\n",
        "  seg_ids = []\n",
        "  current_seg_id = 0              #primeira sentença com valor 0\n",
        "  for tok in tokens:              #percorre cada valor dos tokens\n",
        "    seg_ids.append(current_seg_id) \n",
        "    if tok == \"[SEP]\":            #quando tiver um separador, SEP, entre as sentenças, então coloca na lista valor 1\n",
        "      current_seg_id = 1 - current_seg_id\n",
        "  return seg_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-yS-MVlrBL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fb96d31-239c-4f05-c857-3357f5fec217"
      },
      "source": [
        "#primeira sentenças com os tokens\n",
        "print(data_inputs[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'aw', '##w', '##w', 'that', \"'\", 's', 'a', 'bum', '##mer', '.', 'you', 'should', '##a', 'got', 'david', 'carr', 'of', 'third', 'day', 'to', 'do', 'it', '.', 'd', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD8l4tu7rFle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6580cde9-93f2-43da-81f0-50dccff64f55"
      },
      "source": [
        "#sequencia de 0: indica que é a primeira sentença\n",
        "get_segments(data_inputs[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZLiezqersLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e086e32d-cbc2-4879-a0ca-bef57b9d9b8f"
      },
      "source": [
        "my_sent = [\"[CLS]\"] + tokenizer.tokenize(\"Roses are red.\") + [\"[SEP]\"]\n",
        "my_sent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]', 'roses', 'are', 'red', '.', '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6ZYXw8Kr44J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3aa891-6ef9-4f96-f8db-f96fae583354"
      },
      "source": [
        "#adiciona 3 camadas de INPUT\n",
        "bert_layer([\n",
        "            tf.expand_dims(tf.cast(get_ids(my_sent), tf.int32), 0),     #expande as dimensões precisando estar no formato de BATCH\n",
        "            tf.expand_dims(tf.cast(get_mask(my_sent), tf.int32), 0),\n",
        "            tf.expand_dims(tf.cast(get_segments(my_sent), tf.int32), 0) \n",
        "           ])\n",
        "#tf.cast() = converte de tipo\n",
        "#tf.cast(get_ids(my_sent), tf.int32), 0) = converte os ids da sentença para int32 e0 pois coloca uma dimensão a mais no início\n",
        "\n",
        "#RETORNA 2 MATRIZ DE EMBEDDING: esse retorno é o final, ou seja, escolher qual retorno quer/precisa\n",
        "'''\n",
        "  RETORNO 1: shape=(1, 768) = usado para a CLASSIFICAÇÃO   -> 1 registro para 768 colunas\n",
        "  RETORNO 2: shape=(1, 6, 768) = 1 registro/frase com 6 palavras e 768 colunas\n",
        "                                nível de token, representação de cada palavra\n",
        " '''\n",
        "#shape=(1, 768) = 1: tem uma sentença, resultado do valor 0 colocado no final, adicionaod uma dimensão\n",
        "#                 768: matriz de embedding das colunas          \n",
        "\n",
        "#shape=(1, 6, 768) = 6: tem seis tokens nessa frase"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
              " array([[-9.27935541e-01, -4.10335153e-01, -9.65755045e-01,\n",
              "          9.07317877e-01,  8.12913775e-01, -1.74174339e-01,\n",
              "          9.11234558e-01,  3.41952085e-01, -8.74521315e-01,\n",
              "         -9.99989271e-01, -7.78409958e-01,  9.69385207e-01,\n",
              "          9.86160457e-01,  6.36963248e-01,  9.48631227e-01,\n",
              "         -7.51193166e-01, -4.58339661e-01, -7.08104372e-01,\n",
              "          4.62098330e-01, -6.57927096e-01,  7.60414422e-01,\n",
              "          9.99994814e-01, -3.96861106e-01,  3.44166011e-01,\n",
              "          6.16488576e-01,  9.94400024e-01, -7.76633739e-01,\n",
              "          9.38316464e-01,  9.59452212e-01,  7.32879102e-01,\n",
              "         -6.93436623e-01,  2.93080389e-01, -9.93785501e-01,\n",
              "         -1.64551780e-01, -9.67019558e-01, -9.95549500e-01,\n",
              "          5.32935381e-01, -6.88060820e-01,  1.34715075e-02,\n",
              "          2.98195817e-02, -9.18356419e-01,  4.20526296e-01,\n",
              "          9.99988914e-01,  2.52676070e-01,  6.06235385e-01,\n",
              "         -3.50750059e-01, -1.00000000e+00,  4.97585416e-01,\n",
              "         -8.95187259e-01,  9.62561011e-01,  9.43730652e-01,\n",
              "          9.03285563e-01,  1.54699579e-01,  5.86143613e-01,\n",
              "          5.80860376e-01, -4.05052841e-01, -2.76642758e-02,\n",
              "          2.98045933e-01, -2.83075690e-01, -6.47424281e-01,\n",
              "         -6.51523590e-01,  5.43847322e-01, -9.56302047e-01,\n",
              "         -9.22750354e-01,  9.61462975e-01,  8.27475369e-01,\n",
              "         -3.50112438e-01, -4.06405687e-01, -8.74317735e-02,\n",
              "         -9.98738334e-02,  8.96688342e-01,  3.00931484e-01,\n",
              "         -1.51129678e-01, -8.52713346e-01,  8.09592485e-01,\n",
              "          4.00989205e-01, -6.61605954e-01,  1.00000000e+00,\n",
              "         -6.16246223e-01, -9.86407101e-01,  8.90942991e-01,\n",
              "          8.11157703e-01,  5.81394672e-01, -6.33873343e-01,\n",
              "          3.78197879e-01, -1.00000000e+00,  6.76351190e-01,\n",
              "         -2.30612502e-01, -9.92552459e-01,  3.85461122e-01,\n",
              "          6.57650709e-01, -2.90105700e-01,  4.46832597e-01,\n",
              "          6.28524184e-01, -5.58409274e-01, -6.65294886e-01,\n",
              "         -4.72272217e-01, -9.28039253e-01, -3.54472429e-01,\n",
              "         -6.19735777e-01,  1.24534771e-01, -3.48905593e-01,\n",
              "         -4.23184186e-01, -4.20834899e-01,  4.56588477e-01,\n",
              "         -6.14470840e-01, -5.15243173e-01,  5.01909733e-01,\n",
              "          4.29147959e-01,  7.59821892e-01,  4.37516570e-01,\n",
              "         -4.33598191e-01,  6.30961895e-01, -9.59743083e-01,\n",
              "          7.73877382e-01, -3.95737946e-01, -9.87354457e-01,\n",
              "         -6.73180223e-01, -9.92996335e-01,  7.77800083e-01,\n",
              "         -5.05856276e-01, -3.19990963e-01,  9.69388723e-01,\n",
              "         -3.51620376e-01,  3.79092127e-01, -2.21649349e-01,\n",
              "         -9.51505721e-01, -1.00000000e+00, -8.80426824e-01,\n",
              "         -8.34713101e-01, -2.77321488e-01, -4.70461130e-01,\n",
              "         -9.83711898e-01, -9.56730187e-01,  6.61120892e-01,\n",
              "          9.56025779e-01,  1.62189141e-01,  9.99961436e-01,\n",
              "         -5.11205792e-01,  9.59530532e-01, -5.58610082e-01,\n",
              "         -8.00221145e-01,  8.48543942e-01, -5.58320284e-01,\n",
              "          8.33738446e-01,  2.63149559e-01, -7.33846545e-01,\n",
              "          3.16189587e-01, -4.83306080e-01,  6.87450171e-01,\n",
              "         -7.94889808e-01, -3.81298304e-01, -8.71706128e-01,\n",
              "         -9.49488044e-01, -3.62460047e-01,  9.51175570e-01,\n",
              "         -7.62520730e-01, -9.61278021e-01, -1.53294221e-01,\n",
              "         -4.02463377e-01, -5.69815516e-01,  8.52475762e-01,\n",
              "          7.99818039e-01,  5.33586383e-01, -6.96546674e-01,\n",
              "          4.84272391e-01,  2.24440947e-01,  7.31195211e-01,\n",
              "         -8.18207920e-01, -3.58149767e-01,  5.32028437e-01,\n",
              "         -4.41676110e-01, -9.25720930e-01, -9.87607241e-01,\n",
              "         -5.07007658e-01,  5.31485498e-01,  9.93827105e-01,\n",
              "          7.66175151e-01,  4.12393093e-01,  8.83270323e-01,\n",
              "         -3.85666430e-01,  8.81850243e-01, -9.67345119e-01,\n",
              "          9.86407399e-01, -3.13535571e-01,  3.57363999e-01,\n",
              "         -6.57590389e-01,  2.70097196e-01, -8.59112918e-01,\n",
              "          2.32003912e-01,  8.62852991e-01, -9.03662443e-01,\n",
              "         -7.94610023e-01, -2.82699078e-01, -4.76583600e-01,\n",
              "         -5.01097322e-01, -8.80422235e-01,  5.45586109e-01,\n",
              "         -4.41977441e-01, -5.77728808e-01, -1.25809923e-01,\n",
              "          9.06031966e-01,  9.80562150e-01,  8.44253302e-01,\n",
              "          5.20119965e-01,  7.80579507e-01, -9.23414171e-01,\n",
              "         -5.87243676e-01,  2.34754592e-01,  2.97746927e-01,\n",
              "          3.54463726e-01,  9.96218681e-01, -8.01237464e-01,\n",
              "         -2.79998332e-01, -9.39948797e-01, -9.83751893e-01,\n",
              "          3.82992849e-02, -9.28821802e-01, -2.94137836e-01,\n",
              "         -7.00600863e-01,  7.67863750e-01, -3.51922125e-01,\n",
              "          6.57684088e-01,  5.54106951e-01, -9.90459263e-01,\n",
              "         -7.80433893e-01,  5.50272822e-01, -5.03932893e-01,\n",
              "          5.56852579e-01, -3.53224188e-01,  7.86349893e-01,\n",
              "          9.69607115e-01, -6.54101908e-01,  7.34232903e-01,\n",
              "          8.81996512e-01, -9.14772153e-01, -7.82534599e-01,\n",
              "          8.52741241e-01, -4.38667685e-01,  8.24172020e-01,\n",
              "         -7.77354479e-01,  9.91627038e-01,  9.48048592e-01,\n",
              "          7.74401665e-01, -9.52811837e-01, -7.52400339e-01,\n",
              "         -8.65391135e-01, -8.10665250e-01, -1.91085383e-01,\n",
              "          6.22543804e-02,  9.39342856e-01,  6.60155296e-01,\n",
              "          5.10392964e-01,  3.03855151e-01, -7.58786023e-01,\n",
              "          9.97947216e-01, -8.39390755e-01, -9.73821640e-01,\n",
              "         -6.96808219e-01, -4.71226186e-01, -9.92139816e-01,\n",
              "          9.27336931e-01,  3.11118215e-01,  6.17148757e-01,\n",
              "         -5.93245268e-01, -7.30744064e-01, -9.74081159e-01,\n",
              "          9.14184034e-01,  2.35106945e-01,  9.90232766e-01,\n",
              "         -4.98075485e-01, -9.59739506e-01, -7.62371182e-01,\n",
              "         -9.30913270e-01, -4.32067364e-02, -2.13116273e-01,\n",
              "         -6.06085539e-01, -2.81609371e-02, -9.69718397e-01,\n",
              "          6.36244178e-01,  6.35316253e-01,  5.37905455e-01,\n",
              "         -8.91036153e-01,  9.99303162e-01,  1.00000000e+00,\n",
              "          9.73003685e-01,  9.01396811e-01,  8.87466490e-01,\n",
              "         -9.99958754e-01, -6.90021753e-01,  9.99997973e-01,\n",
              "         -9.93730545e-01, -1.00000000e+00, -9.37510788e-01,\n",
              "         -8.12253356e-01,  2.70660788e-01, -1.00000000e+00,\n",
              "         -2.87078947e-01, -1.50920227e-01, -9.31140304e-01,\n",
              "          8.18555057e-01,  9.78328943e-01,  9.94965494e-01,\n",
              "         -1.00000000e+00,  8.81453574e-01,  9.30843115e-01,\n",
              "         -7.06026912e-01,  9.76767182e-01, -6.08330131e-01,\n",
              "          9.75543439e-01,  5.93019485e-01,  5.54319084e-01,\n",
              "         -2.44307160e-01,  4.22843516e-01, -9.68066394e-01,\n",
              "         -9.14158344e-01, -7.75702834e-01, -7.79753447e-01,\n",
              "          9.98873413e-01,  2.67525762e-01, -7.70680785e-01,\n",
              "         -9.30970311e-01,  6.98258281e-01, -1.79436088e-01,\n",
              "          1.48644924e-01, -9.69404399e-01, -3.27199608e-01,\n",
              "          7.69222736e-01,  8.38437498e-01,  2.74363160e-01,\n",
              "          4.46673781e-01, -6.88233852e-01,  4.38525289e-01,\n",
              "         -6.96209446e-02,  2.83885479e-01,  6.96684837e-01,\n",
              "         -9.55272675e-01, -5.49684346e-01, -3.89560997e-01,\n",
              "          3.75222951e-01, -7.64762223e-01, -9.54122901e-01,\n",
              "          9.69721138e-01, -4.86066371e-01,  9.72205758e-01,\n",
              "          1.00000000e+00,  7.64813542e-01, -9.13303554e-01,\n",
              "          6.57082498e-01,  4.31852072e-01, -7.01079488e-01,\n",
              "          1.00000000e+00,  8.67337048e-01, -9.83669579e-01,\n",
              "         -5.84471822e-01,  7.79540777e-01, -6.77889943e-01,\n",
              "         -7.74523675e-01,  9.99660969e-01, -3.41092885e-01,\n",
              "         -8.14479887e-01, -6.48069501e-01,  9.86273050e-01,\n",
              "         -9.94089246e-01,  9.97643054e-01, -8.94537687e-01,\n",
              "         -9.79997158e-01,  9.60477769e-01,  9.49231923e-01,\n",
              "         -6.83828115e-01, -7.17898488e-01,  2.86706775e-01,\n",
              "         -7.60040998e-01,  4.78332460e-01, -9.51963365e-01,\n",
              "          8.08321118e-01,  5.27614236e-01, -1.67665794e-01,\n",
              "          9.16267991e-01, -8.87898982e-01, -5.93431115e-01,\n",
              "          3.90307903e-01, -7.76923180e-01, -3.84818614e-01,\n",
              "          9.59038138e-01,  6.78381205e-01, -4.08702791e-01,\n",
              "         -1.99682098e-02, -4.68428612e-01, -7.41143227e-01,\n",
              "         -9.73734379e-01,  6.23253882e-01,  1.00000000e+00,\n",
              "         -4.31855559e-01,  8.94348681e-01, -5.72569609e-01,\n",
              "         -1.89498831e-02,  7.24832416e-02,  6.05421424e-01,\n",
              "          5.64564109e-01, -5.04034936e-01, -8.33653092e-01,\n",
              "          9.20378566e-01, -9.70664799e-01, -9.92627263e-01,\n",
              "          8.63119423e-01,  2.32818380e-01, -3.05338413e-01,\n",
              "          9.99999225e-01,  6.51024342e-01,  3.69558573e-01,\n",
              "          5.16951799e-01,  9.89937365e-01, -5.10577671e-02,\n",
              "          5.19780993e-01,  9.13519561e-01,  9.89344180e-01,\n",
              "         -4.06514376e-01,  6.72227561e-01,  8.66246045e-01,\n",
              "         -9.63320851e-01, -3.93905371e-01, -7.32534111e-01,\n",
              "          6.66498989e-02, -9.50428963e-01,  5.36766499e-02,\n",
              "         -9.64523613e-01,  9.78591144e-01,  9.72525179e-01,\n",
              "          5.02412856e-01,  3.42612654e-01,  8.20066929e-01,\n",
              "          1.00000000e+00, -8.37067723e-01,  5.97411335e-01,\n",
              "         -4.17201638e-01,  8.81286025e-01, -9.99911010e-01,\n",
              "         -8.37778151e-01, -4.66961980e-01, -2.72496700e-01,\n",
              "         -9.03814495e-01, -4.58637774e-01,  3.91833425e-01,\n",
              "         -9.79059339e-01,  9.10196304e-01,  8.29555273e-01,\n",
              "         -9.92893577e-01, -9.93933320e-01, -5.58821261e-01,\n",
              "          7.86012113e-01,  2.98600823e-01, -9.94314432e-01,\n",
              "         -8.16725373e-01, -6.58431649e-01,  9.07821953e-01,\n",
              "         -4.84595805e-01, -9.59578693e-01, -5.24700999e-01,\n",
              "         -4.26523209e-01,  5.39447308e-01, -3.51429582e-01,\n",
              "          6.03988051e-01,  8.84236634e-01,  6.91960275e-01,\n",
              "         -7.73553491e-01, -3.49987090e-01, -1.82105884e-01,\n",
              "         -8.09592426e-01,  9.06841516e-01, -8.09706092e-01,\n",
              "         -9.76247609e-01, -2.70705551e-01,  1.00000000e+00,\n",
              "         -5.54332495e-01,  8.93760324e-01,  7.55229712e-01,\n",
              "          7.80316174e-01, -1.99225381e-01,  3.35151106e-01,\n",
              "          9.55944061e-01,  3.82269621e-01, -7.57196665e-01,\n",
              "         -9.39320028e-01, -6.35581493e-01, -6.07328892e-01,\n",
              "          7.00571656e-01,  7.23613143e-01,  7.29011178e-01,\n",
              "          8.65883470e-01,  7.64537513e-01,  2.08820909e-01,\n",
              "         -6.98528513e-02, -5.64421003e-04,  9.99799311e-01,\n",
              "         -4.44099873e-01, -1.80671543e-01, -4.89859432e-01,\n",
              "         -2.91431397e-01, -4.25409138e-01, -1.98749751e-01,\n",
              "          1.00000000e+00,  3.56601954e-01,  7.75661528e-01,\n",
              "         -9.93823767e-01, -9.28070962e-01, -9.31738496e-01,\n",
              "          1.00000000e+00,  8.50040257e-01, -7.60715783e-01,\n",
              "          7.18036413e-01,  7.75469124e-01, -1.75162017e-01,\n",
              "          8.09469342e-01, -3.36547583e-01, -3.02385271e-01,\n",
              "          4.57467973e-01,  3.08043659e-01,  9.70232010e-01,\n",
              "         -6.18903995e-01, -9.75721180e-01, -5.94948828e-01,\n",
              "          5.63390851e-01, -9.66651082e-01,  9.99981284e-01,\n",
              "         -6.10340357e-01, -3.60575110e-01, -4.96435732e-01,\n",
              "         -4.91436511e-01,  4.47817057e-01,  2.87385993e-02,\n",
              "         -9.83154714e-01, -3.47387314e-01,  3.09110731e-01,\n",
              "          9.66638982e-01,  3.75864059e-01, -6.41106606e-01,\n",
              "         -8.90264690e-01,  8.92269194e-01,  8.32000017e-01,\n",
              "         -9.59132135e-01, -9.57766414e-01,  9.71166313e-01,\n",
              "         -9.84971106e-01,  7.67819285e-01,  1.00000000e+00,\n",
              "          3.83998901e-01,  4.38051522e-01,  3.52292359e-01,\n",
              "         -4.46136475e-01,  4.46569175e-01, -6.90631390e-01,\n",
              "          6.74425364e-01, -9.59155798e-01, -4.53284889e-01,\n",
              "         -2.96152532e-01,  3.57684344e-01, -2.41154343e-01,\n",
              "         -5.88313937e-01,  7.63308048e-01,  3.13667178e-01,\n",
              "         -6.03100598e-01, -6.84795499e-01, -2.60147154e-01,\n",
              "          5.75160384e-01,  9.16844189e-01, -3.56800050e-01,\n",
              "         -2.31557816e-01,  1.15727715e-01, -1.77119002e-01,\n",
              "         -9.47563529e-01, -5.23141980e-01, -6.04617774e-01,\n",
              "         -9.99998629e-01,  5.41667700e-01, -1.00000000e+00,\n",
              "          6.60001814e-01,  3.39036673e-01, -2.57962286e-01,\n",
              "          8.98433924e-01,  3.58503461e-01,  7.80091822e-01,\n",
              "         -8.63456011e-01, -9.04243767e-01,  2.35173613e-01,\n",
              "          8.47542048e-01, -4.83704925e-01, -7.76437402e-01,\n",
              "         -7.77086556e-01,  4.51546848e-01, -1.20643966e-01,\n",
              "          3.45337689e-01, -7.58304596e-01,  7.38663435e-01,\n",
              "         -2.54878253e-01,  1.00000000e+00,  1.56726673e-01,\n",
              "         -6.47172928e-01, -9.80846465e-01,  3.21544796e-01,\n",
              "         -3.49479914e-01,  1.00000000e+00, -8.88086140e-01,\n",
              "         -9.70758736e-01,  4.17613685e-01, -6.59506202e-01,\n",
              "         -8.39061558e-01,  4.56445903e-01,  7.08391443e-02,\n",
              "         -8.59648824e-01, -9.68725741e-01,  9.56583917e-01,\n",
              "          8.95311177e-01, -6.79162562e-01,  7.91996121e-01,\n",
              "         -3.77204716e-01, -5.99682212e-01,  1.89219058e-01,\n",
              "          9.34770465e-01,  9.87944484e-01,  7.07965016e-01,\n",
              "          9.21087801e-01, -1.59540907e-01, -4.83467579e-01,\n",
              "          9.76640463e-01,  2.95251906e-01,  5.32053232e-01,\n",
              "          3.22658151e-01,  1.00000000e+00,  4.97991771e-01,\n",
              "         -9.31000829e-01, -3.24744433e-01, -9.82841611e-01,\n",
              "         -2.67996222e-01, -9.52166080e-01,  4.53916699e-01,\n",
              "          3.94372195e-01,  9.26190138e-01, -3.09752285e-01,\n",
              "          9.69366431e-01, -9.40263808e-01,  1.66798502e-01,\n",
              "         -8.32233071e-01, -7.04411268e-01,  5.49370408e-01,\n",
              "         -9.30373430e-01, -9.88702416e-01, -9.91572201e-01,\n",
              "          7.38682628e-01, -5.26327014e-01, -9.29530337e-02,\n",
              "          2.77955979e-01,  2.54385382e-01,  5.55893064e-01,\n",
              "          5.70780277e-01, -1.00000000e+00,  9.51999545e-01,\n",
              "          5.82980812e-01,  9.13394034e-01,  9.78624403e-01,\n",
              "          7.49032319e-01,  7.39971757e-01,  3.71186465e-01,\n",
              "         -9.89660680e-01, -9.84848499e-01, -5.31397760e-01,\n",
              "         -3.88979614e-01,  8.49413693e-01,  8.17016959e-01,\n",
              "          8.92696738e-01,  6.16891980e-01, -5.75284541e-01,\n",
              "         -2.86467463e-01, -7.60570705e-01, -7.78939545e-01,\n",
              "         -9.94441688e-01,  5.72188079e-01, -7.72195101e-01,\n",
              "         -9.57696319e-01,  9.67420757e-01, -2.17979208e-01,\n",
              "         -1.75552770e-01, -3.26557338e-01, -9.06777918e-01,\n",
              "          9.35597420e-01,  7.66239405e-01,  1.90595999e-01,\n",
              "          1.53928876e-01,  5.40217221e-01,  9.02483582e-01,\n",
              "          9.40388918e-01,  9.88884807e-01, -9.10143912e-01,\n",
              "          7.88359880e-01, -8.31383049e-01,  6.11195207e-01,\n",
              "          8.21669102e-01, -9.41967666e-01,  3.75133097e-01,\n",
              "          5.49405694e-01, -6.15318239e-01,  3.91501755e-01,\n",
              "         -3.66627097e-01, -9.74752367e-01,  8.88878226e-01,\n",
              "         -3.62838119e-01,  6.53205752e-01, -5.35069764e-01,\n",
              "         -2.21281331e-02, -4.40158010e-01, -3.87567282e-01,\n",
              "         -7.89354801e-01, -6.70902312e-01,  6.87370062e-01,\n",
              "          4.34680283e-01,  9.07510817e-01,  9.13953960e-01,\n",
              "         -1.07544757e-01, -8.54991794e-01, -3.22965682e-01,\n",
              "         -7.80992687e-01, -9.35075402e-01,  9.56621110e-01,\n",
              "         -2.46967509e-01, -1.84675872e-01,  7.18141794e-01,\n",
              "          1.66833997e-01,  9.54272628e-01,  5.20279586e-01,\n",
              "         -5.11346459e-01, -3.58430475e-01, -7.76734471e-01,\n",
              "          9.01378989e-01, -6.45810246e-01, -6.68203115e-01,\n",
              "         -6.79575562e-01,  8.30889225e-01,  4.56939995e-01,\n",
              "          9.99998212e-01, -8.61587405e-01, -9.52708602e-01,\n",
              "         -5.74054718e-01, -4.75623280e-01,  5.11585772e-01,\n",
              "         -7.02607393e-01, -1.00000000e+00,  5.05624294e-01,\n",
              "         -6.52045965e-01,  8.13730657e-01, -8.72139275e-01,\n",
              "          8.09319854e-01, -8.18222165e-01, -9.88196373e-01,\n",
              "         -4.00082529e-01,  3.38945210e-01,  7.67013729e-01,\n",
              "         -5.16352773e-01, -8.75940800e-01,  6.15952253e-01,\n",
              "         -7.52709627e-01,  9.89328504e-01,  8.95710647e-01,\n",
              "         -6.14250183e-01,  2.19649538e-01,  7.52754331e-01,\n",
              "         -8.20389748e-01, -8.05691242e-01,  9.38039243e-01]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 6, 768), dtype=float32, numpy=\n",
              " array([[[-0.07947513,  0.00580787, -0.31414014, ..., -0.45097244,\n",
              "           0.29333133,  0.23387688],\n",
              "         [ 0.3931604 ,  0.5033638 ,  0.24021432, ..., -0.32635677,\n",
              "           0.3498609 ,  0.20673229],\n",
              "         [ 0.35789207,  0.10767116, -0.04988845, ..., -0.5082272 ,\n",
              "           0.25048867, -0.26268798],\n",
              "         [-0.2989215 , -0.24708748,  0.07151444, ..., -0.33810034,\n",
              "           0.12699437, -0.09681879],\n",
              "         [-0.36815315, -0.71465284, -0.2103259 , ...,  0.35395196,\n",
              "           0.3343857 , -0.6233478 ],\n",
              "         [ 0.88692284, -0.16996934, -0.29173723, ...,  0.0581655 ,\n",
              "          -0.57759917, -0.3207531 ]]], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMRbo5StiA3W"
      },
      "source": [
        "[-0.07947513,  0.00580787, -0.31414014, ..., -0.45097244,\n",
        "           0.29333133,  0.23387688],\n",
        "\n",
        "         [ 0.3931604 ,  0.5033638 ,  0.24021432, ..., -0.32635677,\n",
        "           0.3498609 ,  0.20673229],\n",
        "\n",
        "         [ 0.35789207,  0.10767116, -0.04988845, ..., -0.5082272 ,\n",
        "           0.25048867, -0.26268798],\n",
        "\n",
        "         [-0.2989215 , -0.24708748,  0.07151444, ..., -0.33810034,\n",
        "           0.12699437, -0.09681879],\n",
        "\n",
        "         [-0.36815315, -0.71465284, -0.2103259 , ...,  0.35395196,\n",
        "           0.3343857 , -0.6233478 ],\n",
        "\n",
        "         [ 0.88692284, -0.16996934, -0.29173723, ...,  0.0581655 ,\n",
        "          -0.57759917, -0.3207531 ]\n",
        "\n",
        "shape=(1,6,768):\n",
        "\n",
        "Para cada palavra dessa frase, ou seja, as 6 palavras de 1 frase, cada palavra tem um embedding de 768 colunas\n",
        "\n",
        "ESSA É A REPRESENTAÇÃO QUE SERÁ CONSTRUÍDO O MODELO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbw_VIA4uDCX"
      },
      "source": [
        "data_with_len = [[sent, data_labels[i], len(sent)]\n",
        "                 for i, sent in enumerate(data_inputs)]\n",
        "random.shuffle(data_with_len)\n",
        "data_with_len.sort(key = lambda x: x[2])\n",
        "sorted_all = [([get_ids(sent_lab[0]),\n",
        "               get_mask(sent_lab[0]),\n",
        "               get_segments(sent_lab[0])],\n",
        "               sent_lab[1])\n",
        "              for sent_lab in data_with_len if sent_lab[2] > 7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkMiqmzsfo6a"
      },
      "source": [
        "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n",
        "                                             output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkGWlzeOfos6"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "all_batched = all_dataset.padded_batch(BATCH_SIZE,\n",
        "                                       padded_shapes=((3, None), ()),\n",
        "                                       padding_values=(0, 0)) # 0 = token de padding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aA7it--hHl4"
      },
      "source": [
        "NB_BATCHES = len(sorted_all) // BATCH_SIZE\n",
        "NB_BATCHES_TEST = NB_BATCHES // 10\n",
        "all_batched.shuffle(NB_BATCHES)\n",
        "test_dataset = all_batched.take(NB_BATCHES_TEST)\n",
        "train_dataset = all_batched.skip(NB_BATCHES_TEST)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2pxAPFxGe8r"
      },
      "source": [
        "# Etapa 3: Construção do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6DD3k3qPLDQ"
      },
      "source": [
        "class DCNNBERTEmbedding(tf.keras.Model):\n",
        "    \n",
        "    #construtor\n",
        "    def __init__(self,\n",
        "                 nb_filters=50,\n",
        "                 FFN_units=512,\n",
        "                 nb_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 name=\"dcnn\"):\n",
        "        super(DCNNBERTEmbedding, self).__init__(name=name)\n",
        "        \n",
        "        #camada de embedding;      treinable = false: não será treinado o modelo, apenas usado 16min:35s aula 10\n",
        "        self.bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                                         trainable = False)\n",
        "\n",
        "        self.bigram = layers.Conv1D(filters=nb_filters,\n",
        "                                    kernel_size=2,\n",
        "                                    padding=\"valid\",\n",
        "                                    activation=\"relu\")\n",
        "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
        "                                     kernel_size=3,\n",
        "                                     padding=\"valid\",\n",
        "                                     activation=\"relu\")\n",
        "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
        "                                      kernel_size=4,\n",
        "                                      padding=\"valid\",\n",
        "                                      activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if nb_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=nb_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    #camada de embedding: BERT será uma camada de embedding no treinamento\n",
        "    def embed_with_bert(self, all_tokens):\n",
        "      #_, emb = : _ => descarta o que o all_tokens retorna por primeiro, que é a representação da frase inteira e pega apenas o 2º vetor: shape=(1,6,768)\n",
        "      _, embs = self.bert_layer([all_tokens[:, 0, :],\n",
        "                                 all_tokens[:, 1, :],\n",
        "                                 all_tokens[:, 2, :]])\n",
        "      return embs\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        x = self.embed_with_bert(inputs)\n",
        "        \n",
        "        x_1 = self.bigram(x)\n",
        "        x_1 = self.pool(x_1)\n",
        "        x_2 = self.trigram(x)\n",
        "        x_2 = self.pool(x_2)\n",
        "        x_3 = self.fourgram(x)\n",
        "        x_3 = self.pool(x_3)\n",
        "        \n",
        "        #concatena  as 3 camadas convolucionais de trainamento\n",
        "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
        "        merged = self.dense_1(merged)\n",
        "        merged = self.dropout(merged, training)\n",
        "        output = self.last_dense(merged)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsWpzQz2IQvJ"
      },
      "source": [
        "# Etapa 4: Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhfUFvWEPOIf"
      },
      "source": [
        "NB_FILTERS = 100\n",
        "FFN_UNITS = 256\n",
        "NB_CLASSES = 2\n",
        "DROPOUT_RATE = 0.2\n",
        "BATCH_SIZE = 32\n",
        "NB_EPOCHS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HPbZ72KPPnX"
      },
      "source": [
        "#rede neural convolucional\n",
        "Dcnn = DCNNBERTEmbedding(nb_filters=NB_FILTERS,\n",
        "                         FFN_units=FFN_UNITS,\n",
        "                         nb_classes=NB_CLASSES,\n",
        "                         dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpHDseF0QLl3"
      },
      "source": [
        "if NB_CLASSES == 2:\n",
        "    Dcnn.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "else:\n",
        "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1hdT_JT2Rfi"
      },
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/IA MachineLearning DataSciense/BERT-classificacao_sentimentos/sentimentos\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest checkpoint restored!!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8LHztku2cjl"
      },
      "source": [
        "#salva o modeo a cada época\n",
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        ckpt_manager.save()\n",
        "        print(\"Checkpoint saved at {}.\".format(checkpoint_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrT8oWZzQNmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "243a0994-c6d2-4633-efcf-57cfe378ee82"
      },
      "source": [
        "history = Dcnn.fit(train_dataset,\n",
        "                   epochs=NB_EPOCHS,\n",
        "                   steps_per_epoch = 200,\n",
        "                   callbacks=[MyCustomCallback()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.8659Checkpoint saved at /content/drive/MyDrive/IA MachineLearning DataSciense/BERT-classificacao_sentimentos/sentimentos.\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.3232 - accuracy: 0.8659\n",
            "Epoch 2/5\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3231 - accuracy: 0.8645Checkpoint saved at /content/drive/MyDrive/IA MachineLearning DataSciense/BERT-classificacao_sentimentos/sentimentos.\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.3231 - accuracy: 0.8645\n",
            "Epoch 3/5\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3163 - accuracy: 0.8648Checkpoint saved at /content/drive/MyDrive/IA MachineLearning DataSciense/BERT-classificacao_sentimentos/sentimentos.\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3163 - accuracy: 0.8648\n",
            "Epoch 4/5\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3151 - accuracy: 0.8683Checkpoint saved at /content/drive/MyDrive/IA MachineLearning DataSciense/BERT-classificacao_sentimentos/sentimentos.\n",
            "200/200 [==============================] - 16s 81ms/step - loss: 0.3151 - accuracy: 0.8683\n",
            "Epoch 5/5\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.8737Checkpoint saved at /content/drive/MyDrive/IA MachineLearning DataSciense/BERT-classificacao_sentimentos/sentimentos.\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.3056 - accuracy: 0.8737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CdL-Qb00czr"
      },
      "source": [
        "Epoch 1/5\n",
        "  40623/Unknown - 2999s 74ms/step - loss: 0.3973 - accuracy: 0.8219Checkpoint saved at /content/drive/My Drive/Cursos - recursos.\n",
        "40623/40623 [==============================] - 3001s 74ms/step - loss: 0.3973 - accuracy: 0.8219\n",
        "Epoch 2/5\n",
        "40623/40623 [==============================] - ETA: 0s - loss: 0.3756 - accuracy: 0.8339Checkpoint saved at /content/drive/My Drive/Cursos - recursos.\n",
        "40623/40623 [==============================] - 2987s 74ms/step - loss: 0.3756 - accuracy: 0.8339\n",
        "Epoch 3/5\n",
        "40623/40623 [==============================] - ETA: 0s - loss: 0.3659 - accuracy: 0.8391Checkpoint saved at /content/drive/My Drive/Cursos - recursos.\n",
        "40623/40623 [==============================] - 2979s 73ms/step - loss: 0.3659 - accuracy: 0.8391\n",
        "Epoch 4/5\n",
        "40623/40623 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.8426Checkpoint saved at /content/drive/My Drive/Cursos - recursos.\n",
        "40623/40623 [==============================] - 2969s 73ms/step - loss: 0.3586 - accuracy: 0.8426\n",
        "Epoch 5/5\n",
        "40623/40623 [==============================] - ETA: 0s - loss: 0.3527 - accuracy: 0.8454Checkpoint saved at /content/drive/My Drive/Cursos - recursos.\n",
        "40623/40623 [==============================] - 2960s 73ms/step - loss: 0.3527 - accuracy: 0.8454\n",
        "<tensorflow.python.keras.callbacks.History at 0x7fd363ef4080>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAb_ijA5Idmz"
      },
      "source": [
        "# Etapa 5: Avaliação do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J40Z7iWIBR4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b331859c-617f-45c9-e0b7-83f33f021245"
      },
      "source": [
        "results = Dcnn.evaluate(test_dataset)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4513/4513 [==============================] - 268s 59ms/step - loss: 0.3259 - accuracy: 0.8619\n",
            "[0.325869619846344, 0.8618712425231934]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAnePWaPCLVf"
      },
      "source": [
        "def get_prediction(sentence):\n",
        "  tokens = encode_sentence(sentence)\n",
        "\n",
        "  input_ids = get_ids(tokens)\n",
        "  input_mask = get_mask(tokens)\n",
        "  segment_ids = get_segments(tokens)\n",
        "\n",
        "  #empilha as camadas\n",
        "  inputs = tf.stack(\n",
        "      [\n",
        "       tf.cast(input_ids, dtype=tf.int32),\n",
        "       tf.cast(input_mask, dtype=tf.int32),\n",
        "       tf.cast(segment_ids, dtype=tf.int32),\n",
        "      ], axis = 0)\n",
        "  inputs = tf.expand_dims(inputs, 0) #0 indicação de 1 registro\n",
        "\n",
        "  output = Dcnn(inputs, training=False)\n",
        "\n",
        "  sentiment = math.floor(output*2)\n",
        "\n",
        "  if sentiment == 0:\n",
        "    print(\"Output of the model: {}\\nPredicted sentiment: negative\".format(output))\n",
        "  elif sentiment == 1:\n",
        "    print(\"Output of the model: {}\\nPredicted sentiment: positive\".format(output))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb_7IGY_DaqL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a630a183-9500-42d8-ce42-910c94cda230"
      },
      "source": [
        "get_prediction(\"This actor is very bad.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output of the model: [[0.0178184]]\n",
            "Predicted sentiment: negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73nVjcmmDymB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "660006de-5276-418c-8fa0-21cfcbd80d42"
      },
      "source": [
        "get_prediction(\"I like dogs.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output of the model: [[0.9603923]]\n",
            "Predicted sentiment: positive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}